{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(20) if x == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadFileinZipFile(zip_filename, dtypes=None, parsedate = None, password=None, **kvargs):\n",
    "    \"\"\"\n",
    "    Load zipfile to dataframe.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as myzip:\n",
    "        if password:\n",
    "            myzip.setpassword(password)\n",
    "\n",
    "        inside_zip_filename = myzip.filelist[0].filename\n",
    "\n",
    "        if parsedate:\n",
    "            pd_data = pd.read_csv(myzip.open(inside_zip_filename), sep=',', parse_dates=parsedate, dtype=dtypes, **kvargs)\n",
    "        else:\n",
    "            pd_data = pd.read_csv(myzip.open(inside_zip_filename), sep=',', dtype=dtypes, **kvargs)\n",
    "        return pd_data, inside_zip_filename\n",
    "    \n",
    "def create_dataset1(pd_data):\n",
    "    \n",
    "    #filling na with -999 so that there is no overlap with none Na values\n",
    "    pd_data = pd_data.fillna(-999)\n",
    "    \n",
    "    #Label encoding categorical variable\n",
    "    for col in pd_data.select_dtypes(['object']):\n",
    "        pd_data[col] = pd.factorize(pd_data[col])[0]\n",
    "    \n",
    "    #Extracting train and test data\n",
    "    pd_train = pd_data[pd_data.target >= 0]\n",
    "    pd_test = pd_data[pd_data.target == -1]\n",
    "\n",
    "    Y = pd_train['target'].values\n",
    "    X = np.array(pd_train.drop(['target','ID'],1))\n",
    "    X_test = np.array(pd_test.drop(['ID'],1))\n",
    "    test_idx = pd_test['ID']\n",
    "    \n",
    "    return X, Y, X_test, test_idx\n",
    "\n",
    "def create_dataset2(pd_data):\n",
    "    \n",
    "    #filling na with -999 so that there is no overlap with none Na values\n",
    "    pd_data = pd_data.fillna(-999)\n",
    "    \n",
    "    #Label encoding categorical variable\n",
    "    for col in pd_data.select_dtypes(['object']):\n",
    "        pd_data[col] = pd.factorize(pd_data[col])[0]\n",
    "    \n",
    "    #Extracting train and test data\n",
    "    pd_train = pd_data[pd_data.target >= 0]\n",
    "    pd_test = pd_data[pd_data.target == -1]\n",
    "\n",
    "    Y = pd_train['target'].values\n",
    "    X = np.array(pd_train.drop(['target','ID'],1))\n",
    "    X_test = np.array(pd_test.drop(['ID'],1))\n",
    "    test_idx = pd_test['ID']\n",
    "    \n",
    "    return X, Y, X_test, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = \"/home/ardalan/Documents/kaggle/bnp/data/\"\n",
    "\n",
    "#Loading datasets\n",
    "pd_train, _ = loadFileinZipFile(folder + \"train.csv.zip\")\n",
    "pd_test, _ = loadFileinZipFile(folder + \"test.csv.zip\")\n",
    "\n",
    "#Merging datasets into one DataFrame\n",
    "pd_test['target'] = -1\n",
    "pd_data = pd_train.append(pd_test).reset_index(drop=True)\n",
    "\n",
    "#getting dataset1\n",
    "X, Y, X_test, test_idx = create_dataset1(pd_data)\n",
    "D1 = (X, Y, X_test, test_idx)\n",
    "\n",
    "X, Y, X_test, test_idx = create_dataset2(pd_data)\n",
    "D2 = (X, Y, X_test, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def models():\n",
    "    \n",
    "    clfs = [\n",
    "        [D1, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D1, ExtraTreesClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D2, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D3, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D4, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D5, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D6, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D7, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "        [D8, RandomForestClassifier(n_estimators=20, n_jobs=8, max_depth=10)],\n",
    "    ]\n",
    "    return clfs\n",
    "\n",
    "\n",
    "clfs = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 8, 6, ..., 2, 6, 1],\n",
       "       [8, 7, 2, ..., 7, 2, 3],\n",
       "       [8, 3, 4, ..., 5, 3, 9],\n",
       "       ..., \n",
       "       [8, 9, 5, ..., 2, 3, 4],\n",
       "       [2, 2, 2, ..., 4, 2, 5],\n",
       "       [7, 7, 1, ..., 9, 5, 6]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier [0]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=8,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold [0]\n",
      "0.462327192606 0.49178501286\n",
      "Fold [1]\n",
      "0.457616495516 0.486886104061\n",
      "Fold [2]\n",
      "0.458760349588 0.487374256865\n",
      "Fold [3]\n",
      "0.456442443075 0.48817378845\n",
      "Classifier [1]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=8,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fold [0]\n",
      "0.459728124188 0.489453693541\n",
      "Fold [1]\n",
      "0.459457126707 0.490049838357\n",
      "Fold [2]\n",
      "0.460448811722 0.488687025857\n",
      "Fold [3]\n",
      "0.45952782975 0.488483327379\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(Y, n_iter=4, test_size=0.2, random_state=123)\n",
    "\n",
    "#Cross validation from a list of models\n",
    "for clf_indice, data_clf in enumerate(clfs):\n",
    "    \n",
    "    #Selecting a model from the list\n",
    "    print(\"Classifier [%i]\" % clf_indice)\n",
    "    \n",
    "    X = data_clf[0][0]\n",
    "    Y = data_clf[0][1]\n",
    "    X_test = data_clf[0][2]\n",
    "    test_idx = data_clf[0][3]\n",
    "    \n",
    "    clf = data_clf[1]\n",
    "    print(clf)\n",
    "    \n",
    "    for fold_indice, (tr_idx, te_idx) in enumerate(skf):\n",
    "        \n",
    "        print(\"Fold [%i]\" % fold_indice)\n",
    "        xtrain = X[tr_idx]\n",
    "        ytrain = Y[tr_idx]\n",
    "        xval = X[te_idx]\n",
    "        yval = Y[te_idx]\n",
    "        \n",
    "        clf.fit(xtrain, ytrain)\n",
    "        \n",
    "        y_train_pred = clf.predict_proba(xtrain)\n",
    "        y_val_pred = clf.predict_proba(xval)\n",
    "        \n",
    "        train_error = log_loss(ytrain, y_train_pred)\n",
    "        val_error = log_loss(yval, y_val_pred)\n",
    "        print(train_error, val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We create two datasets:\n",
    "    - One by Label Encoding categorical columns\n",
    "    - One by One Hot Encoding categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the first dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = np.random.randint(1,10, (10000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 8, 6, ..., 2, 6, 1],\n",
       "       [8, 7, 2, ..., 7, 2, 3],\n",
       "       [8, 3, 4, ..., 5, 3, 9],\n",
       "       ..., \n",
       "       [8, 9, 5, ..., 2, 3, 4],\n",
       "       [2, 2, 2, ..., 4, 2, 5],\n",
       "       [7, 7, 1, ..., 9, 5, 6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
